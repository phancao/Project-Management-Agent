# Testing Guide - Project Management Agent

HÆ°á»›ng dáº«n chi tiáº¿t vá» cÃ¡ch test tá»«ng pháº§n cá»§a há»‡ thá»‘ng Project Management Agent.

## ğŸ“ Test Organization

The project has two types of test files:

1. **Official Test Suite** (`tests/` directory): Automated unit and integration tests run via pytest
2. **Standalone Test Scripts** (`scripts/tests/` directory): Manual testing, debugging, and validation scripts

### Creating New Test Scripts

**For AI Assistants**: When creating new test scripts:
- **Standalone/debugging scripts**: Create in `scripts/tests/` directory
- **Unit/integration tests**: Create in `tests/` directory (follow pytest conventions)
- See `scripts/tests/README.md` for detailed guidelines

## ğŸš€ Quick Start

### Cháº¡y test nhanh
```bash
# Test nhanh táº¥t cáº£ components
python quick_test.py

# Hoáº·c sá»­ dá»¥ng Makefile
make test
```

### Cháº¡y test chi tiáº¿t
```bash
# Test táº¥t cáº£
python run_tests.py all

# Test tá»«ng pháº§n
python run_tests.py deerflow
python run_tests.py conversation
python run_tests.py database
python run_tests.py api
```

### Cháº¡y standalone test scripts
```bash
# Run standalone test scripts (manual testing/debugging)
python scripts/tests/test_openproject_all_pagination.py
```

## ğŸ“‹ Test Suites

### 1. DeerFlow Integration Tests (`tests/test_deerflow.py`)

**Má»¥c Ä‘Ã­ch**: Test tÃ­ch há»£p DeerFlow vá»›i OpenAI API

**CÃ¡c test bao gá»“m**:
- âœ… Import cÃ¡c module DeerFlow
- âœ… Káº¿t ná»‘i LLM vá»›i OpenAI API
- âœ… XÃ¢y dá»±ng graph workflow
- âœ… Cháº¡y workflow Ä‘Æ¡n giáº£n
- âœ… Cháº¡y workflow research
- âœ… Kiá»ƒm tra configuration

**Cháº¡y test**:
```bash
python run_tests.py deerflow
# hoáº·c
python tests/test_deerflow.py
```

**Káº¿t quáº£ mong Ä‘á»£i**:
```
ğŸ¦Œ Running DeerFlow Integration Tests...
âœ… Configuration loaded successfully
âœ… LLM import successful
âœ… Graph builder import successful
âœ… Workflow import successful
âœ… LLM connection works
âœ… Graph built successfully
âœ… Workflow completed successfully
ğŸ‰ All tests passed! DeerFlow integration is working correctly.
```

### 2. Conversation Flow Manager Tests (`tests/test_conversation_flow.py`)

**Má»¥c Ä‘Ã­ch**: Test há»‡ thá»‘ng quáº£n lÃ½ conversation flow

**CÃ¡c test bao gá»“m**:
- âœ… Import conversation flow manager
- âœ… PhÃ¢n loáº¡i intent tá»« message
- âœ… Táº¡o cÃ¢u há»i clarification
- âœ… Quáº£n lÃ½ context conversation
- âœ… Validation dá»¯ liá»‡u
- âœ… Chuyá»ƒn Ä‘á»•i tráº¡ng thÃ¡i flow
- âœ… Luá»“ng conversation hoÃ n chá»‰nh

**Cháº¡y test**:
```bash
python run_tests.py conversation
# hoáº·c
python tests/test_conversation_flow.py
```

**Káº¿t quáº£ mong Ä‘á»£i**:
```
ğŸ’¬ Running Conversation Flow Manager Tests...
âœ… Conversation Flow Manager imports successful
âœ… Intent classification works
âœ… Question generation works
âœ… Data validation works
âœ… Context management works
âœ… Flow state transitions work
âœ… Complete conversation flow works
ğŸ‰ All tests passed! Conversation Flow Manager is working correctly.
```

### 3. Database Model Tests (`tests/test_database.py`)

**Má»¥c Ä‘Ã­ch**: Test cÃ¡c model database vÃ  validation

**CÃ¡c test bao gá»“m**:
- âœ… Import database models
- âœ… Táº¡o vÃ  validation models
- âœ… Test enum values
- âœ… Test relationships giá»¯a models
- âœ… Test JSON serialization
- âœ… Test optional fields
- âœ… Test timestamps
- âœ… Test UUID generation

**Cháº¡y test**:
```bash
python run_tests.py database
# hoáº·c
python tests/test_database.py
```

**Káº¿t quáº£ mong Ä‘á»£i**:
```
ğŸ—„ï¸ Running Database Tests...
âœ… Database models import successful
âœ… Model creation works
âœ… Model validation works
âœ… Enum values work
âœ… Relationships work
âœ… JSON serialization works
âœ… Optional fields work
âœ… Timestamps work
âœ… UUID generation works
ğŸ‰ All tests passed! Database models are working correctly.
```

### 4. FastAPI Endpoint Tests (`tests/test_api.py`)

**Má»¥c Ä‘Ã­ch**: Test cÃ¡c API endpoints vÃ  WebSocket

**CÃ¡c test bao gá»“m**:
- âœ… Import FastAPI app
- âœ… Health check endpoint
- âœ… Chat endpoints
- âœ… Project management endpoints
- âœ… Task management endpoints
- âœ… Research endpoints
- âœ… Knowledge base endpoints
- âœ… WebSocket connection
- âœ… Data validation
- âœ… Error handling

**Cháº¡y test**:
```bash
python run_tests.py api
# hoáº·c
python tests/test_api.py
```

**Káº¿t quá»£i mong Ä‘á»£i**:
```
ğŸ”Œ Running FastAPI Tests...
âœ… FastAPI app import successful
âœ… Health check works
âœ… Chat endpoints work
âœ… Project endpoints work
âœ… Task endpoints work
âœ… Research endpoints work
âœ… Knowledge endpoints work
âœ… WebSocket connection works
âœ… Data validation works
âœ… Error handling works
ğŸ‰ All tests passed! FastAPI is working correctly.
```

## ğŸ› ï¸ Development Testing

### Cháº¡y development environment
```bash
# Start all services
make dev

# Hoáº·c manual
docker-compose up -d postgres redis
uv run uvicorn api.main:app --reload --port 8000
cd frontend && npm run dev
```

### Test vá»›i Docker
```bash
# Build vÃ  test vá»›i Docker
docker-compose up --build

# Test specific service
docker-compose up api
docker-compose up frontend
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. DeerFlow tests fail
```
âŒ LLM connection failed: AuthenticationError
```
**Giáº£i phÃ¡p**: Kiá»ƒm tra API key trong `conf.yaml`

#### 2. Conversation tests fail
```
âŒ Conversation Flow Manager imports failed: ModuleNotFoundError
```
**Giáº£i phÃ¡p**: Cháº¡y `uv sync` Ä‘á»ƒ cÃ i dependencies

#### 3. API tests fail
```
âŒ FastAPI app import failed: ImportError
```
**Giáº£i phÃ¡p**: Kiá»ƒm tra imports trong `api/main.py`

#### 4. Database tests fail
```
âŒ Database models import failed: ImportError
```
**Giáº£i phÃ¡p**: Kiá»ƒm tra file `database/models.py`

### Debug mode
```bash
# Cháº¡y test vá»›i debug output
python -u tests/test_deerflow.py

# Cháº¡y vá»›i verbose output
python run_tests.py deerflow --verbose
```

## ğŸ“Š Test Coverage

### Kiá»ƒm tra coverage
```bash
# Install coverage tools
uv add pytest-cov

# Run tests with coverage
uv run pytest --cov=src --cov=api --cov=database tests/
```

### Coverage report
```bash
# Generate HTML coverage report
uv run pytest --cov=src --cov-report=html tests/
open htmlcov/index.html
```

## ğŸš€ Continuous Integration

### GitHub Actions (náº¿u cÃ³)
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Install dependencies
        run: |
          pip install uv
          uv sync
      - name: Run tests
        run: python run_tests.py all
```

## ğŸ“ Best Practices

### 1. Test Structure
- Má»—i test file test má»™t component cá»¥ thá»ƒ
- Test cases rÃµ rÃ ng vÃ  dá»… hiá»ƒu
- Error messages chi tiáº¿t

### 2. Test Data
- Sá»­ dá»¥ng mock data cho tests
- Clean up sau má»—i test
- Test vá»›i edge cases

### 3. Performance
- Test timeout Ä‘á»ƒ trÃ¡nh hang
- Test vá»›i realistic data sizes
- Monitor test execution time

### 4. Maintenance
- Update tests khi thay Ä‘á»•i code
- Review test failures ngay láº­p tá»©c
- Document test requirements

## ğŸ¯ Next Steps

Sau khi táº¥t cáº£ tests pass:

1. **Start development server**:
   ```bash
   make dev
   ```

2. **Access the application**:
   - Frontend: http://localhost:3000
   - API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

3. **Test manual integration**:
   - Táº¡o project má»›i
   - Test conversation flow
   - Test real-time chat

4. **Deploy to production**:
   ```bash
   make deploy
   ```

---

**Happy Testing! ğŸ§ªâœ¨**
