2025-11-03 12:00:21,349 - __main__ - INFO - Starting DeerFlow API server on localhost:8000
2025-11-03 12:00:21,349 - __main__ - INFO - Log level: INFO
2025-11-03 12:00:23,054 - src.graph.checkpoint - WARNING - Checkpoint saver is disabled
2025-11-03 12:00:23,080 - src.server.app - INFO - Allowed origins: ['http://localhost:3000']
INFO:     Started server process [33024]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)
2025-11-03 12:00:26,681 - src.conversation.flow_manager - INFO - LLM-based intent classifier initialized
2025-11-03 12:00:26,681 - src.conversation.flow_manager - INFO - LLM-based data extractor initialized
2025-11-03 12:00:26,686 - src.conversation.flow_manager - INFO - PM Provider initialized: OpenProjectProvider
2025-11-03 12:00:26,750 - src.conversation.flow_manager - INFO - Self-learning system initialized
2025-11-03 12:00:26,751 - src.server.app - INFO - Created global ConversationFlowManager singleton
INFO:     ::1:49893 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:00:26,754 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:00:26,754 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:00:29,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:00:29,538 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.78s
2025-11-03 12:00:29,538 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch the active project context to the demo project for focused work.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Demo Project",
      "description": "Set demo project as the active project for focused work",
      "requires_context": false
    }
  ]
}
2025-11-03 12:00:29,538 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 2.78s
2025-11-03 12:00:29,538 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 2.78s
2025-11-03 12:00:29,538 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 2.78s
2025-11-03 12:00:29,538 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 2.78s
2025-11-03 12:00:29,538 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 2.78s
2025-11-03 12:00:30,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:00:30,183 - src.conversation.flow_manager - WARNING - Could not find JSON in LLM response: null
2025-11-03 12:00:30,183 - src.conversation.flow_manager - INFO - Extracted initial data: {}
2025-11-03 12:00:30,183 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:00:32,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:00:32,682 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.50s
2025-11-03 12:00:32,682 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch the active project context to the demo project for focused work.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Demo Project",
      "description": "Set demo project as the active project for focused work",
      "requires_context": false
    }
  ]
}
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 2.50s
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - [TIMING] Plan has 1 steps - 0.00s
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/1: Switch to Demo Project - 0.00s
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - Executing PM step: switch_project
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - Handling SWITCH_PROJECT intent
2025-11-03 12:00:32,683 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 0.00s - 0.00s total
2025-11-03 12:00:32,683 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 3.15s
2025-11-03 12:00:32,684 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 5.93s
INFO:     ::1:49912 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:00:44,649 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:00:44,649 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:00:47,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:00:47,474 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.83s
2025-11-03 12:00:47,474 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch the active project context to the Demo project for focused work.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Demo Project",
      "description": "Set Demo project as the active project for focused work",
      "requires_context": false
    }
  ]
}
2025-11-03 12:00:47,474 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 2.83s
2025-11-03 12:00:47,474 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 2.83s
2025-11-03 12:00:47,475 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 2.83s
2025-11-03 12:00:47,475 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 2.83s
2025-11-03 12:00:47,475 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 2.83s
2025-11-03 12:00:47,475 - src.conversation.flow_manager - INFO - Final current_state: FlowState.COMPLETED, intent: IntentType.UNKNOWN
2025-11-03 12:00:47,475 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 0.00s
2025-11-03 12:00:47,475 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 2.83s
INFO:     ::1:49960 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:00:59,463 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:00:59,463 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:01:03,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:01:03,128 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 3.67s
2025-11-03 12:01:03,129 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch the active project context to the Demo project for focused work.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Demo Project",
      "description": "Set Demo project as the active project for focused work",
      "requires_context": false
    }
  ]
}
2025-11-03 12:01:03,129 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 3.67s
2025-11-03 12:01:03,129 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 3.67s
2025-11-03 12:01:03,129 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 3.67s
2025-11-03 12:01:03,129 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 3.67s
2025-11-03 12:01:03,129 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 3.67s
2025-11-03 12:01:04,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:01:04,596 - src.conversation.flow_manager - INFO - Extracted data: {'project_name': 'Demo project', 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': 3, 'tasks': None}
2025-11-03 12:01:04,596 - src.conversation.flow_manager - INFO - Extracted initial data: {'project_name': 'Demo project', 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': 3, 'tasks': None}
2025-11-03 12:01:04,597 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:01:07,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.54s
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch the active project context to Demo project for focused work.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Demo Project",
      "description": "Set Demo project as the active project for focused work",
      "requires_context": false
    }
  ]
}
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 2.54s
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:01:07,141 - src.conversation.flow_manager - INFO - [TIMING] Plan has 1 steps - 0.00s
2025-11-03 12:01:07,142 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/1: Switch to Demo Project - 0.00s
2025-11-03 12:01:07,142 - src.conversation.flow_manager - INFO - Executing PM step: switch_project
2025-11-03 12:01:07,142 - src.conversation.flow_manager - INFO - Handling SWITCH_PROJECT intent
2025-11-03 12:01:07,215 - src.conversation.flow_manager - INFO - Found project 'Demo project' with ID: 1
2025-11-03 12:01:07,216 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 0.07s - 0.07s total
2025-11-03 12:01:07,216 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 4.09s
2025-11-03 12:01:07,216 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 7.75s
INFO:     ::1:51156 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:27:31,194 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:27:31,194 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:27:34,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:27:34,133 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.94s
2025-11-03 12:27:34,133 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will analyze task dependencies in the project. First, I need to list tasks, then research dependencies, and provide recommendations.",
  "steps": [
    {
      "step_type": "list_tasks",
      "title": "List Current Project Tasks",
      "description": "Retrieve all tasks in the current project for dependency analysis",
      "requires_context": true
    },
    {
      "step_type": "research",
      "title": "Analyze Task Dependencies",
      "description": "Research and identify dependencies between tasks, critical paths, and blockers",
      "requires_context": true
    }
  ]
}
2025-11-03 12:27:34,133 - src.conversation.flow_manager - INFO - Generated PM plan with 2 steps in 2.94s
2025-11-03 12:27:34,133 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 2.94s
2025-11-03 12:27:34,133 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 2.94s
2025-11-03 12:27:34,133 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 2.94s
2025-11-03 12:27:34,133 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 2.94s
2025-11-03 12:27:35,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:27:35,588 - src.conversation.flow_manager - INFO - Extracted data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': None}
2025-11-03 12:27:35,588 - src.conversation.flow_manager - INFO - Extracted initial data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': None}
2025-11-03 12:27:35,589 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:27:38,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 3.40s
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will analyze task dependencies in the current project. First, I need to list tasks and then research dependencies to provide insights.",
  "steps": [
    {
      "step_type": "list_tasks",
      "title": "List Current Project Tasks",
      "description": "Retrieve all tasks in the current project for dependency analysis",
      "requires_context": true
    },
    {
      "step_type": "research",
      "title": "Analyze Task Dependencies",
      "description": "Research and identify dependencies between tasks, critical paths, and blockers",
      "requires_context": true
    }
  ]
}
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Generated PM plan with 2 steps in 3.40s
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Generated PM plan with 2 steps
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] Plan has 2 steps - 0.00s
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/2: List Current Project Tasks - 0.00s
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Executing PM step: list_tasks
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Handling LIST_TASKS intent
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 0.00s - 0.00s total
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - [TIMING] Executing step 2/2: Analyze Task Dependencies - 0.00s
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:27:38,985 - src.conversation.flow_manager - INFO - Handling generic research: Analyze Task Dependencies
2025-11-03 12:27:53,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:27:53,305 - src.conversation.flow_manager - INFO - Generic research completed: 5023 chars
2025-11-03 12:27:53,305 - src.conversation.flow_manager - INFO - [TIMING] Step 2 completed in 14.32s - 14.32s total
2025-11-03 12:27:53,305 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 19.17s
2025-11-03 12:27:53,306 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 22.11s
INFO:     ::1:51194 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:27:58,779 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:27:58,779 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:28:02,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:02,108 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 3.33s
2025-11-03 12:28:02,108 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will first switch the active context to project 1, then analyze dependencies within that project.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Project 1",
      "description": "Activate project 1 as the current working context for further tasks.",
      "requires_context": false
    },
    {
      "step_type": "list_tasks",
      "title": "List Current Project Tasks for Dependency Analysis",
      "description": "Retrieve all tasks in project 1 for understanding dependencies.",
      "requires_context": true
    },
    {
      "step_type": "research",
      "title": "Analyze Task Dependencies",
      "description": "Research and identify dependencies between tasks, critical paths, and blockers within project 1.",
      "requires_context": true
    }
  ]
}
2025-11-03 12:28:02,108 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps in 3.33s
2025-11-03 12:28:02,108 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 3.33s
2025-11-03 12:28:02,108 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 3.33s
2025-11-03 12:28:02,109 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 3.33s
2025-11-03 12:28:02,109 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 3.33s
2025-11-03 12:28:03,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:03,727 - src.conversation.flow_manager - INFO - Extracted data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': ['switch to project 1', 'analyze dependencies']}
2025-11-03 12:28:03,727 - src.conversation.flow_manager - INFO - Extracted initial data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': ['switch to project 1', 'analyze dependencies']}
2025-11-03 12:28:03,727 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:28:07,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:07,275 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 3.55s
2025-11-03 12:28:07,275 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will switch to project 1 for focused work and then analyze the dependencies of tasks within it.",
  "steps": [
    {
      "step_type": "switch_project",
      "title": "Switch to Project 1",
      "description": "Activate project 1 for focused work on tasks and analysis.",
      "requires_context": false
    },
    {
      "step_type": "list_tasks",
      "title": "List Current Project Tasks",
      "description": "Retrieve all tasks in project 1 for dependency analysis.",
      "requires_context": true
    },
    {
      "step_type": "research",
      "title": "Analyze Task Dependencies",
      "description": "Research and identify dependencies between tasks, critical paths, and blockers for project 1.",
      "requires_context": true
    }
  ]
}
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps in 3.55s
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Plan has 3 steps - 0.00s
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/3: Switch to Project 1 - 0.00s
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Executing PM step: switch_project
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Handling SWITCH_PROJECT intent
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 0.00s - 0.00s total
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Executing step 2/3: List Current Project Tasks - 0.00s
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Executing PM step: list_tasks
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Handling LIST_TASKS intent
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Step 2 completed in 0.00s - 0.00s total
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - [TIMING] Executing step 3/3: Analyze Task Dependencies - 0.00s
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:28:07,276 - src.conversation.flow_manager - INFO - Handling generic research: Analyze Task Dependencies
2025-11-03 12:28:22,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:22,077 - src.conversation.flow_manager - INFO - Generic research completed: 4165 chars
2025-11-03 12:28:22,077 - src.conversation.flow_manager - INFO - [TIMING] Step 3 completed in 14.80s - 14.80s total
2025-11-03 12:28:22,077 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 19.97s
2025-11-03 12:28:22,077 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 23.30s
INFO:     ::1:51247 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:28:32,747 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:28:32,747 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:28:34,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:34,984 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 2.24s
2025-11-03 12:28:34,985 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will research best practices for sprint planning to provide comprehensive guidance.",
  "steps": [
    {
      "step_type": "research",
      "title": "Research Sprint Planning Best Practices",
      "description": "Research industry best practices, frameworks, and techniques for effective sprint planning to enhance team efficiency and productivity.",
      "requires_context": false
    }
  ]
}
2025-11-03 12:28:34,985 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 2.24s
2025-11-03 12:28:34,985 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 2.24s
2025-11-03 12:28:34,985 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 2.24s
2025-11-03 12:28:34,985 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 2.24s
2025-11-03 12:28:34,985 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 2.24s
2025-11-03 12:28:36,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:36,202 - src.conversation.flow_manager - WARNING - Could not find JSON in LLM response: null
2025-11-03 12:28:36,202 - src.conversation.flow_manager - INFO - Extracted initial data: {}
2025-11-03 12:28:36,202 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:28:38,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 1.93s
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will research best practices for sprint planning to provide comprehensive guidance.",
  "steps": [
    {
      "step_type": "research",
      "title": "Research Sprint Planning Best Practices",
      "description": "Research industry best practices, frameworks, and techniques for conducting effective sprint planning sessions.",
      "requires_context": false
    }
  ]
}
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps in 1.94s
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - Generated PM plan with 1 steps
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - [TIMING] Plan has 1 steps - 0.00s
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/1: Research Sprint Planning Best Practices - 0.00s
2025-11-03 12:28:38,137 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:28:38,137 - src.conversation.flow_manager - WARNING - Research step for sprint planning should be handled by SPRINT_PLANNING step instead
2025-11-03 12:28:40,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:40,878 - src.conversation.flow_manager - INFO - Thinking plan LLM response: ```json
{
  "thought": "I will assess project tasks, evaluate team capacity, and plan sprints with prioritized task assignments.",
  "steps": [
    "Review project backlog to identify available tasks for sprints",
    "Calculate team capacity based on member availability and sprint duration",
    "Prioritize and select tasks that align with team capacity for the sprint",
    "Assign tasks to team members and document sprint plan"
  ]
}
```
2025-11-03 12:28:40,878 - src.conversation.flow_manager - INFO - Extracted thinking plan: {'thought': 'I will assess project tasks, evaluate team capacity, and plan sprints with prioritized task assignments.', 'steps': ['Review project backlog to identify available tasks for sprints', 'Calculate team capacity based on member availability and sprint duration', 'Prioritize and select tasks that align with team capacity for the sprint', 'Assign tasks to team members and document sprint plan']}
2025-11-03 12:28:40,878 - src.conversation.flow_manager - INFO - Handling SPRINT_PLANNING intent
2025-11-03 12:28:40,887 - src.conversation.flow_manager - INFO - SPRINT_PLANNING - project_id: None
2025-11-03 12:28:40,887 - src.conversation.flow_manager - INFO - SPRINT_PLANNING - gathered_data: {'_pm_plan': {'locale': 'en-US', 'overall_thought': 'I will research best practices for sprint planning to provide comprehensive guidance.', 'steps': [{'step_type': 'research', 'title': 'Research Sprint Planning Best Practices', 'description': 'Research industry best practices, frameworks, and techniques for conducting effective sprint planning sessions.', 'requires_context': False, 'execution_res': None}]}, '_current_step_index': 0}
2025-11-03 12:28:40,887 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 2.75s - 2.75s total
2025-11-03 12:28:40,887 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 5.90s
2025-11-03 12:28:40,887 - src.server.app - INFO - [PM-CHAT-TIMING] Total response time: 8.14s
INFO:     ::1:51290 - "POST /api/pm/chat/stream HTTP/1.1" 200 OK
2025-11-03 12:28:50,326 - src.server.app - INFO - [PM-CHAT-TIMING] generate_stream started
2025-11-03 12:28:50,326 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:28:54,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:54,733 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 4.41s
2025-11-03 12:28:54,733 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will provide a clear comparison of Agile and Waterfall methodologies, outlining their key features and differences.",
  "steps": [
    {
      "step_type": "research",
      "title": "Research Agile Methodology",
      "description": "Gather information on Agile methodology, including its principles, frameworks, and benefits.",
      "requires_context": false
    },
    {
      "step_type": "research",
      "title": "Research Waterfall Methodology",
      "description": "Gather information on Waterfall methodology, including its phases, characteristics, and advantages.",
      "requires_context": false
    },
    {
      "step_type": "research",
      "title": "Compare Agile and Waterfall Methodologies",
      "description": "Analyze and compare the key features, pros and cons, and ideal use cases of Agile vs Waterfall.",
      "requires_context": true
    }
  ]
}
2025-11-03 12:28:54,733 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps in 4.41s
2025-11-03 12:28:54,733 - src.server.app - INFO - [PM-CHAT-TIMING] PM plan generated: 4.41s
2025-11-03 12:28:54,733 - src.server.app - INFO - [PM-CHAT-TIMING] Needs research: False - 4.41s
2025-11-03 12:28:54,734 - src.server.app - INFO - [PM-CHAT-TIMING] process_task started: 4.41s
2025-11-03 12:28:54,734 - src.server.app - INFO - [PM-CHAT-TIMING] process_with_streaming started: 4.41s
2025-11-03 12:28:56,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:28:56,092 - src.conversation.flow_manager - INFO - Extracted data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': None}
2025-11-03 12:28:56,092 - src.conversation.flow_manager - INFO - Extracted initial data: {'project_name': None, 'project_id': None, 'project_description': None, 'domain': None, 'breakdown_levels': None, 'tasks': None}
2025-11-03 12:28:56,092 - src.conversation.flow_manager - INFO - [TIMING] generate_pm_plan started
2025-11-03 12:29:01,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:29:01,094 - src.conversation.flow_manager - INFO - [TIMING] LLM invoke completed: 5.00s
2025-11-03 12:29:01,094 - src.conversation.flow_manager - INFO - PM plan LLM response: {
  "locale": "en-US",
  "overall_thought": "I will clarify the differences between Agile and Waterfall project management methodologies, highlighting key features and use cases.",
  "steps": [
    {
      "step_type": "research",
      "title": "Research Agile Methodology",
      "description": "Gather information on Agile methodology, including its principles, practices, and suitability for projects.",
      "requires_context": false
    },
    {
      "step_type": "research",
      "title": "Research Waterfall Methodology",
      "description": "Gather information on Waterfall methodology, including its stages, characteristics, and appropriate usage.",
      "requires_context": false
    },
    {
      "step_type": "research",
      "title": "Compare Agile and Waterfall Methodologies",
      "description": "Analyze the differences, advantages, and disadvantages between Agile and Waterfall methodologies to provide a clear comparison.",
      "requires_context": true
    }
  ]
}
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps in 5.00s
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - Generated PM plan with 3 steps
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - Final current_state: FlowState.PLANNING_PHASE, intent: IntentType.UNKNOWN
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - [TIMING] _handle_planning_phase started
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - [TIMING] Plan has 3 steps - 0.00s
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - [TIMING] Executing step 1/3: Research Agile Methodology - 0.00s
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:29:01,095 - src.conversation.flow_manager - INFO - Handling generic research: Research Agile Methodology
2025-11-03 12:29:21,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:29:21,040 - src.conversation.flow_manager - INFO - Generic research completed: 5734 chars
2025-11-03 12:29:21,040 - src.conversation.flow_manager - INFO - [TIMING] Step 1 completed in 19.95s - 19.95s total
2025-11-03 12:29:21,040 - src.conversation.flow_manager - INFO - [TIMING] Executing step 2/3: Research Waterfall Methodology - 19.95s
2025-11-03 12:29:21,040 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:29:21,041 - src.conversation.flow_manager - INFO - Handling generic research: Research Waterfall Methodology
2025-11-03 12:29:37,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:29:37,747 - src.conversation.flow_manager - INFO - Generic research completed: 5156 chars
2025-11-03 12:29:37,748 - src.conversation.flow_manager - INFO - [TIMING] Step 2 completed in 16.71s - 36.65s total
2025-11-03 12:29:37,748 - src.conversation.flow_manager - INFO - [TIMING] Executing step 3/3: Compare Agile and Waterfall Methodologies - 36.65s
2025-11-03 12:29:37,748 - src.conversation.flow_manager - INFO - Executing PM step: research
2025-11-03 12:29:37,748 - src.conversation.flow_manager - INFO - Handling generic research: Compare Agile and Waterfall Methodologies
2025-11-03 12:29:54,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-03 12:29:54,900 - src.conversation.flow_manager - INFO - Generic research completed: 5297 chars
2025-11-03 12:29:54,900 - src.conversation.flow_manager - INFO - [TIMING] Step 3 completed in 17.15s - 53.81s total
2025-11-03 12:29:54,900 - src.server.app - INFO - [PM-CHAT-TIMING] process_message completed: 60.17s
